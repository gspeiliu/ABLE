{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gflownet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1SPG2GU0kaR33LeE-Ndkyi_zyMy5tL6WH","authorship_tag":"ABX9TyMNuVOs+99UPdZ3/Z9vYGOK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset,DataLoader\n","import re \n","import json\n","\n","import numpy as np\n","# deleted version only 14 states left \n","class trafficSet(Dataset):\n","    def __init__(self,path,train,g_flag=False):\n","        with open(path,'r') as f:\n","              testset = json.load(f)\n","        actions_set = set()\n","        self.actions = []\n","        self.rewards = []\n","        self.data = []\n","        self.target = []\n","        self.redun_list = []\n","        self.redun_dict = {}\n","        self.states_list = []\n","        for tset in testset:\n","            self.actions.append(tset['actions'])\n","            self.rewards.append(tset['robustness'][0])\n","            for action in tset['actions']:\n","                    actions_set.add(action)\n","        if g_flag is False:\n","          if train is True:\n","              self.data = self.actions[:int(len(self.actions)*0.8)]\n","              self.target = self.rewards[:int(len(self.actions)*0.8)]\n","          else:\n","              self.data = self.actions[int(len(self.actions)*0.8):]\n","              self.target = self.rewards[int(len(self.actions)*0.8):]\n","        else:\n","          self.data = self.actions\n","          self.target = self.rewards\n","            \n","        self.actions_list = sorted(list(actions_set))\n","        self.proxy_actions_list = self.actions_list.copy() + [',','.']\n","        self.actions_to_index = {self.actions_list[i] : i  for i in range(len(self.actions_list))}\n","        self.actions_category = []\n","        self.actions_dict = {}\n","        self.actions_index = []\n","        i = 0\n","        action_string = re.sub(r'[0-9]+', '', self.actions_list[0])\n","        for action in self.actions_list:\n","            current_action =  action[:4] + re.sub(r'[0-9]+', '', action[4:])\n","            if current_action not in self.actions_category:\n","                self.actions_category = self.actions_category + [current_action]\n","                self.actions_index.append(i)\n","                self.actions_dict[current_action] = [action]\n","            else:\n","                self.actions_dict[current_action].append(action)\n","            i = i + 1\n","        \n","        self.proxy_actions_indexes= {}\n","        for i in range(len(self.actions_index)):\n","            if i != len(self.actions_index) -1 :\n","                self.proxy_actions_indexes[self.actions_category[i]] = [self.actions_index[i],self.actions_index[i+1]]\n","            else:\n","                self.proxy_actions_indexes[self.actions_category[i]] = [self.actions_index[i],len(self.actions_list)]\n","            i = i + 1\n","        index = 0\n","        self.actions_category = []\n","        for action in self.actions[0]:\n","          self.actions_category.append(action[:4] + re.sub(r'[0-9]+', '', action[4:]))\n","        remove_category = []\n","        remove_action = []\n","        for category in self.actions_category:\n","          sindex = self.proxy_actions_indexes[category][0]\n","          eindex = self.proxy_actions_indexes[category][1]\n","          if (eindex - sindex) == 1:\n","            self.redun_list.append(category)\n","            self.redun_dict[category] = [index ,sindex]\n","            remove_category.append(category)\n","            remove_action.append(self.actions_list[sindex])\n","          index = index + 1        \n","        for category in remove_category:\n","          self.actions_category.remove(category)\n","        for action in remove_action:\n","          self.actions_list.remove(action)\n","        self.actions_list = self.actions_list + [',','.'] # bos,eos(.) and pad(,) tokens\n","        temp_index = []\n","        temp_category = []\n","        self.actions_indexes = {}\n","        i = 0\n","        last_index = 0\n","        last_action =  self.actions_list[0][:4] + re.sub(r'[0-9]+', '', self.actions_list[0][:4])\n","        temp_category.append(last_action)\n","        for action in self.actions_list:\n","            current_action =  action[:4] + re.sub(r'[0-9]+', '', action[4:])\n","            if current_action not in temp_category:\n","                self.actions_indexes[last_action] = [last_index,i]\n","                last_action = current_action\n","                last_index = i\n","\n","            else:\n","                continue\n","            i = i + 1\n","        self.pad_index = len(self.actions_list) - 2\n","        self.bos_index = len(self.actions_list) - 1\n","        self.max_len = len(self.actions_category) + 1\n","\n","        # self.embeddings = Embedding(len(self.actions_list),emb_dim,self.actions_indexes[','][0])\n","    def __getitem__(self, index):\n","        state = self.actions[index]\n","        state_idx = []\n","        proxy_idx = []\n","        remove_idx = -1\n","        for action in state:\n","            state_idx.append(self.actions_to_index[action])\n","        proxy_idx = state_idx.copy()\n","        count = 0\n","        for redun in self.redun_list:\n","          #print(redun)\n","          state_idx[self.redun_dict[redun][0]] = remove_idx \n","        while remove_idx in state_idx:\n","          state_idx.remove(remove_idx)\n","        # action = [self.actions_indexes['.'][0]] + action  # add <BOS> for every action\n","        state = torch.LongTensor(state_idx)\n","        proxy_state = torch.LongTensor(proxy_idx)\n","        reward = self.rewards[index]\n","        reward = np.exp(reward)\n","        # print(index)\n","        return proxy_state,state,reward\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"ELXqmBRlMvzw","executionInfo":{"status":"ok","timestamp":1656899283538,"user_tz":-480,"elapsed":481,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def gflow2proxy(gflow, redun_list, redun_dict,batch_size,proxy_max_len):\n","  generated = torch.LongTensor(batch_size, proxy_max_len)\n","  generated.fill_(-1)\n","  filled = []\n","  for redun in redun_list:\n","    index, action_id = redun_dict[redun]\n","    generated[:,index] = action_id\n","    filled.append(index)\n","  gflow_index = 0\n","  for i in range(proxy_max_len):\n","    if i in filled:\n","      continue\n","    else:\n","      generated[:,i] = gflow[:,gflow_index]\n","      gflow_index = gflow_index + 1\n","  return generated"],"metadata":{"id":"zr8zaBpBXi_4","executionInfo":{"status":"ok","timestamp":1656899285581,"user_tz":-480,"elapsed":2,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["gflownet_set = trafficSet(\"/content/drive/MyDrive/a_testset_for_double_direction.json\",train=False)\n","proxy_state, state, reward = gflownet_set[0]\n","indexes = gflownet_set.actions_indexes\n","# print(indexes['time+'])\n","# print(gflownet_set.actions_category)\n","# print(gflownet_set.proxy_actions_list[113:137])\n","print(gflownet_set.redun_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gikasfGvOCRn","executionInfo":{"status":"ok","timestamp":1656899287202,"user_tz":-480,"elapsed":529,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"aaa3c45e-21d2-4f65-8a99-d3166509a45a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["['ego+start+lane_position+lane_+.', 'ego+start+speed+.', 'ego+destination+lane_position+lane_+.', 'ego+destination+speed+.', 'npc1+start+lane_position+lane_+.', 'npc1motion++lane_position+lane_+.', 'npc1+destination+lane_position+lane_+.', 'npc1+destination+speed+.', 'npc2+start+lane_position+lane_+.', 'npc2motion++lane_position+lane_+.', 'npc2+destination+lane_position+lane_+.', 'npc2+destination+speed+.', 'npc3+start+lane_position+lane_+.', 'npc3motion++lane_position+lane_+.', 'npc3+destination+lane_position+lane_+.', 'npc3+destination+speed+.', 'npc4+start+lane_position+lane_+.', 'npc4motion++lane_position+lane_+.', 'npc4+destination+lane_position+lane_+.', 'npc4+destination+speed+.', 'npc5+start+lane_position+lane_+.', 'npc5motion++lane_position+lane_+.', 'npc5+destination+lane_position+lane_+.', 'npc5+destination+speed+.']\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(gflownet_set, 2, shuffle=False,)\n","data = None\n","for x in train_dataloader:\n","  data = x\n","  break\n","print(x[0])\n","print(gflow2proxy(x[1],gflownet_set.redun_list,gflownet_set.redun_dict,2,38))\n","print(x[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyBr6ok8lMCW","executionInfo":{"status":"ok","timestamp":1656899288205,"user_tz":-480,"elapsed":2,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"cea5ce24-3812-45c3-a017-930d02d657ad"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[120, 146, 150, 139,   2,   3,   0,   1,   6,  15,  16,  18,   4,   5,\n","          29,  38,  39,  49,  27,  28,  52,  60,  61,  71,  50,  51,  74,  82,\n","          83,  93,  72,  73,  96, 101, 102, 108,  94,  95],\n","        [124, 142, 149, 137,   2,   3,   0,   1,   6,  15,  16,  18,   4,   5,\n","          29,  38,  39,  44,  27,  28,  52,  60,  61,  63,  50,  51,  74,  82,\n","          83,  92,  72,  73,  96, 101, 102, 104,  94,  95]])\n","tensor([[120, 146, 150, 139,   2,   3,   0,   1,   6,  15,  16,  18,   4,   5,\n","          29,  38,  39,  49,  27,  28,  52,  60,  61,  71,  50,  51,  74,  82,\n","          83,  93,  72,  73,  96, 101, 102, 108,  94,  95],\n","        [124, 142, 149, 137,   2,   3,   0,   1,   6,  15,  16,  18,   4,   5,\n","          29,  38,  39,  44,  27,  28,  52,  60,  61,  63,  50,  51,  74,  82,\n","          83,  92,  72,  73,  96, 101, 102, 104,  94,  95]])\n","tensor([[120, 146, 150, 139,  15,  18,  38,  49,  60,  71,  82,  93, 101, 108],\n","        [124, 142, 149, 137,  15,  18,  38,  44,  60,  63,  82,  92, 101, 104]])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","def Embedding(num_embeddings, embedding_dim, padding_idx=None):\n","    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","    nn.init.normal_(m.weight, mean=0, std=embedding_dim ** -0.5)\n","    if padding_idx is not None:\n","        nn.init.constant_(m.weight[padding_idx], 0)\n","    return m\n","    \n","class proxy(nn.Module):\n","    def __init__(self, num_tokens, num_outputs, num_hid,\n","                 num_layers, max_len=60, dropout=0.1,\n","                 partition_init=150.0,):\n","        super(proxy,self).__init__()\n","        self.input = nn.Linear(num_tokens * max_len, num_hid)\n","        hidden_layers = []\n","        for _ in range(num_layers):\n","            hidden_layers.append(nn.Dropout(dropout))\n","            hidden_layers.append(nn.ReLU())\n","            hidden_layers.append(nn.Linear(num_hid, num_hid))\n","        self.hidden = nn.Sequential(*hidden_layers)\n","        self.output = nn.Linear(num_hid, num_outputs)\n","        self.max_len = max_len\n","        self.num_tokens = num_tokens\n","        self.emb = Embedding(self.num_tokens,self.num_tokens)\n","\n","   \n","\n","    def forward(self, x,  return_all=False, lens=None):\n","        x = self.emb(x)\n","        # print(x.shape)\n","        x = x.reshape(x.size(0),-1)\n","        # print(x.shape)\n","        out = self.input(x)\n","        # out = x.reshape(-1)\n","        out = self.hidden(out)\n","        out = self.output(out)\n","        # print(out.shape)\n","        out = out.reshape(-1)\n","        return out\n","\n"],"metadata":{"id":"K155dJlE_kmC","executionInfo":{"status":"ok","timestamp":1656899289953,"user_tz":-480,"elapsed":279,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["proxy_model =  proxy(num_tokens=154,\n","                                num_outputs=1,\n","                                num_hid=1024,\n","                                num_layers=4, # TODO: add these as hyperparameters?\n","                                dropout=0.1,\n","                                max_len=38)\n","proxy_model.load_state_dict(torch.load(\"/content/drive/MyDrive/current_w.pth\",map_location='cpu')['state_dict'])"],"metadata":{"id":"ikyTGNCz_uqB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656899292025,"user_tz":-480,"elapsed":2,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"1e7b1f45-2e14-4aac-e182-e5e30b7597a6"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","gflownet_set = trafficSet(\"/content/drive/MyDrive/a_testset_for_double_direction.json\",train=False)\n","params = AttrDict({\n","    \"n_words\": len(gflownet_set.actions_list), \n","    \"pad_index\" : gflownet_set.pad_index, \n","    \"eos_index\" : gflownet_set.bos_index, \n","    \"bos_index\" : gflownet_set.bos_index,\n","    'max_length': gflownet_set.max_len,\n","    'actions_index':gflownet_set.actions_indexes,\n","    'actions_list': gflownet_set.actions_list,\n","    \"actions_category\":gflownet_set.actions_category,\n","    \"proxy_actions_list\":gflownet_set.proxy_actions_list,\n","    \"emb_dim\" : 256, \n","\n","})\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","import itertools\n","import numpy as np\n","\n","def Embedding(num_embeddings, embedding_dim, padding_idx=None):\n","    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n","    nn.init.normal_(m.weight, mean=0, std=embedding_dim ** -0.5)\n","    if padding_idx is not None:\n","        nn.init.constant_(m.weight[padding_idx], 0)\n","    return m\n","\n","def get_padding_masks(slen, lengths):\n","    \"\"\"\n","    Generate hidden states mask\n","    \"\"\"\n","    assert lengths.max().item() <= slen\n","    bs = lengths.size(0)\n","    alen = torch.arange(slen, dtype=torch.long, device=lengths.device)\n","    mask = alen < lengths[:, None]\n","    # sanity check\n","    assert mask.size() == (bs, slen)\n","    return mask\n","\n","class TransformerModel(nn.Module):\n","\n","    # params : n_words, eos_index, pad_index, emb_dim\n","\n","    def __init__(self, params, transformer_layers):\n","        \"\"\"\n","        Transformer model \n","        \"\"\"\n","        super().__init__()\n","        # embeddings : one hot is better in this case\n","        self.embeddings = Embedding(params.n_words, params.emb_dim, padding_idx=params.pad_index)\n","        # This can be replace by transformer model from torch.nn, huggingface transoformer ...\n","        self.transformer = transformer_layers\n","\n","    def forward(self, x, lengths):\n","        \"\"\"\n","        Inputs:\n","            `x` LongTensor(bs, slen), containing word indices\n","            `lengths` LongTensor(bs), containing the length of each sentence\n","        \"\"\"\n","        #padding_mask = x != self.pad_index\n","        #lengths = padding_mask.long().sum(dim=1).to(x.device)\n","        \n","        # check inputs\n","        bs, slen = x.size()\n","        assert lengths.size(0) == bs\n","        assert lengths.max().item() <= slen\n","\n","        # generate masks\n","        mask = get_padding_masks(slen, lengths)\n","\n","        # embeddings\n","        tensor = self.embeddings(x)\n","        tensor *= mask.unsqueeze(-1).to(tensor.dtype)\n","        \n","        # transformer layers\n","        tensor = self.transformer(tensor)\n","        \n","        return tensor\n","def make_mlp(l, act=nn.LeakyReLU(), tail=[]):\n","    \"\"\"makes an MLP with no top layer activation\"\"\"\n","    return nn.Sequential(*(sum(\n","        [[nn.Linear(i, o)] + ([act] if n < len(l)-2 else [])\n","         for n, (i, o) in enumerate(zip(l, l[1:]))], []) + tail))"],"metadata":{"id":"j02cCX7V_3ls","executionInfo":{"status":"ok","timestamp":1656899294038,"user_tz":-480,"elapsed":639,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logZ = torch.zeros((1,)).to(device)\n","n_hid = 256\n","n_layers = 2\n","mlp = make_mlp([params.emb_dim] + [n_hid] * n_layers + [params.n_words]).to(device)\n","model = TransformerModel(params, mlp).to(device)\n","P_B = 1 # DAG & sequence generation => tree \n","\n","\n","optim = torch.optim.Adam([ {'params':model .parameters(), 'lr':0.0001}, {'params':[logZ], 'lr':0.01} ])\n","logZ.requires_grad_()"],"metadata":{"id":"Y5099ifkAEyp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656899296175,"user_tz":-480,"elapsed":273,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"736aa2ab-663b-4132-f0d2-824ba88fb54a"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.], requires_grad=True)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["a = [1,2,3,4,5,6]\n","a[2:3] = []\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAcHSpvmNIt8","executionInfo":{"status":"ok","timestamp":1656898865309,"user_tz":-480,"elapsed":2,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"ce4970ab-4c45-4ace-e5ad-9f917fcf21f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 4, 5, 6]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["import tqdm\n","\n","losses_TB = []\n","zs_TB = []\n","rewards_TB = []\n","l1log_TB = []"],"metadata":{"id":"GWw4FqzHAFIK","executionInfo":{"status":"ok","timestamp":1656899298232,"user_tz":-480,"elapsed":462,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","a = torch.rand(3,4)\n","print(a)\n","print(F.normalize(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9tuPp6Szp6e","executionInfo":{"status":"ok","timestamp":1656899299742,"user_tz":-480,"elapsed":446,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"c86c5c77-cc08-4b95-9208-f502b6432842"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0568, 0.8325, 0.0148, 0.5216],\n","        [0.9980, 0.3752, 0.7383, 0.2324],\n","        [0.3712, 0.7188, 0.9495, 0.1349]])\n","tensor([[0.0577, 0.8459, 0.0151, 0.5300],\n","        [0.7575, 0.2848, 0.5604, 0.1764],\n","        [0.2958, 0.5729, 0.7568, 0.1076]])\n"]}]},{"cell_type":"code","source":["def softmax_norm(scores,batch_size,vocab_size):\n","  print(scores)\n","  score_tensor = torch.zeros(batch_size,vocab_size)\n","  max_tensor = torch.tensor(torch.max(scores,1).values)\n","  for i in range(batch_size):\n","      score_tensor[i,:].fill_(max_tensor[i]) \n","  scores = scores - score_tensor\n","  print(scores)\n","  return scores"],"metadata":{"id":"lRmQfJ5FD6NM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 2\n","max_len = params.max_length + 0\n","actions_list = params.actions_list\n","actions_index = params.actions_index\n","actions_category = params.actions_category\n","#n_train_steps = 1000\n","n_train_steps = 10000\n","for it in tqdm.trange(n_train_steps):\n","    nan_flag = False\n","    generated = torch.LongTensor(batch_size, max_len)  # upcoming output\n","    generated.fill_(params.pad_index)                  # fill upcoming ouput with <PAD>\n","    generated[:,0].fill_(params.bos_index)             # <BOS> (start token), initial state\n","\n","    # Length of already generated sequences : 1 because of <BOS>\n","    #gen_len = (generated != params.pad_index).long().sum(dim=1)\n","    gen_len = torch.LongTensor(batch_size,).fill_(1) # (batch_size,)\n","    # 1 (True) if the generation of the sequence is not yet finished, 0 (False) otherwise\n","    unfinished_sents = gen_len.clone().fill_(1) # (batch_size,)\n","    # Length of already generated sequences : 1 because of <BOS>\n","    cur_len = 1 \n","\n","    # Z_test = model(generated[:,:cur_len].to(device), lengths=gen_len.to(device))\n","    # #Z_test = Z_test[:,0].squeeze(1).exp().to(device)\n","    # Z_test = Z_test.sum(dim=1).squeeze(1).exp().to(device)\n","    # print(Z_test)\n","\n","    Z = logZ.exp()\n","\n","    flag = True\n","    if flag :\n","        # detached form  of TB\n","        ll_diff = torch.zeros((batch_size,)).to(device)\n","        ll_diff += logZ\n","    else :\n","        # non-detached form of TB ojective, where we multiply everything before doing the logarithm\n","        in_probs = torch.ones(batch_size, dtype=torch.float, requires_grad=True).to(device)\n","\n","    while cur_len < max_len:\n","        state = generated[:,:cur_len] + 0 # (bs, cur_len)\n","        tensor = model(state.to(device), lengths=gen_len.to(device)) # (bs, cur_len, vocab_size)\n","        # print(tensor)\n","        #scores = tensor[:,0] # (bs, vocab_size) : use last word for prediction\n","        scores = tensor.sum(dim=1) # (bs, vocab_size)\n","        \n","        # fixed length generation\n","        cur_action_index = actions_index[actions_category[cur_len-1]]\n","        for index in range(0,cur_action_index[0]):\n","          scores[:,index] = -1e8\n","        for index in range(cur_action_index[1],max_len):\n","          scores[:,index] = -1e8\n","        \n","        scores = scores.log_softmax(1)\n","        \n","        sample_temperature = 100\n","        \n","        # scores = softmax_norm(scores,batch_size,params.n_words)\n","        # break\n","        probs = F.softmax(scores / sample_temperature, dim=1)\n","        # probs = torch.where(torch.isnan(probs),torch.full_like(probs,1e-8),probs)\n","        try:\n","          next_words = torch.multinomial(probs, 1).squeeze(1)\n","        except:\n","          nan_flag = True\n","          break      \n","          \n","        # update generations / lengths / finished sentences / current length\n","        generated[:,cur_len] = next_words.cpu() * unfinished_sents + params.pad_index * (1 - unfinished_sents)\n","        gen_len.add_(unfinished_sents) # add 1 to the length of the unfinished sentences\n","        unfinished_sents.mul_(next_words.cpu().ne(params.eos_index).long()) # as soon as we generate <EOS>, set unfinished_sents to 0\n","        cur_len = cur_len + 1\n","\n","        # loss\n","        if flag :\n","            #sample_in_probs = probs.gather(1, next_words.unsqueeze(-1)).squeeze(1)\n","            #sample_in_probs[unfinished_sents == 0] = 1.\n","            #ll_diff += sample_in_probs.log()\n","            \n","            ll_diff += scores.gather(1, next_words.unsqueeze(-1)).squeeze(1)\n","        else :\n","            sample_in_probs = probs.gather(1, next_words.unsqueeze(-1)).squeeze(1)\n","            sample_in_probs[unfinished_sents == 0] = 1.\n","            in_probs = in_probs * sample_in_probs\n","      \n","        # stop when there is a <EOS> in each sentence, or if we exceed the maximul length\n","        if unfinished_sents.max() == 0:\n","            break\n","    if nan_flag == True:\n","      nan_flag = False\n","      continue\n","\n","    generated = generated.apply_(lambda index : 0 if index == params.pad_index or index == params.eos_index else index)\n","    #R = reward_function(generated, reward_coef, lambda_, beta).to(device)\n","    # generated =  [float(\"\".join([str(s_i) for s_i in s])) for s in generated.tolist()]\n","    # R = reward_function22(generated, reward_coef, lambda_, beta).to(device) \n","    generated = gflow2proxy(generated[:,1:],gflownet_set.redun_list,gflownet_set.redun_dict,batch_size,38)\n","    R = proxy_model(generated)\n","    \n","    optim.zero_grad()\n","    if flag :\n","        ll_diff -= R.log()\n","        loss = (ll_diff**2).sum()/batch_size\n","    else :\n","        loss = ((Z*in_probs / R).log()**2).sum()/batch_size\n","    R = R.detach()\n","    loss.backward()\n","    optim.step()\n","\n","    losses_TB.append(loss.item())\n","    zs_TB.append(Z.item())\n","    rewards_TB.append(R.mean().cpu())\n","    \n","    it = it + batch_size\n","\n","    if it%100==0: \n","        print('\\nloss =', np.array(losses_TB[-100:]).mean(), 'Z =', Z.item(), \"R =\", np.array(rewards_TB[-100:]).mean() )\n","torch.save(model,\"/content/drive/MyDrive/gflownet.pth\")\n","        "],"metadata":{"id":"yT3jN6hxAHYE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07d5e8d0-ba15-4ee5-9f4d-b2d095f21075","executionInfo":{"status":"ok","timestamp":1656899959604,"user_tz":-480,"elapsed":657235,"user":{"displayName":"赵为","userId":"02938840416374213176"}}},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["  1%|          | 100/10000 [00:08<18:36,  8.87it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 2105.6095830165978 Z = 2.4410769939422607 R = 0.7346751\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 202/10000 [00:17<11:13, 14.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1981.20121591568 Z = 6.048422813415527 R = 0.7118993\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 301/10000 [00:24<12:35, 12.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1676.1934630298615 Z = 13.383367538452148 R = 0.7048503\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 401/10000 [00:32<12:37, 12.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1648.7561139941215 Z = 30.363346099853516 R = 0.71638185\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 501/10000 [00:40<12:28, 12.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1572.0145966404677 Z = 68.59188079833984 R = 0.7265577\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▌         | 601/10000 [00:48<13:25, 11.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1715.4976299372286 Z = 164.40628051757812 R = 0.7161111\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 700/10000 [00:56<12:53, 12.03it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1448.1725125766616 Z = 349.4123229980469 R = 0.7276864\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 800/10000 [01:04<13:24, 11.44it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1478.7409080616098 Z = 782.388671875 R = 0.7066065\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 900/10000 [01:11<11:39, 13.01it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1357.9622291874884 Z = 1691.0767822265625 R = 0.71710885\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1000/10000 [01:19<12:36, 11.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1271.3222414930165 Z = 3529.434326171875 R = 0.71985275\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 1100/10000 [01:27<11:29, 12.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1494.6746837070025 Z = 8525.7080078125 R = 0.71735007\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1200/10000 [01:34<11:29, 12.75it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1295.3409770452977 Z = 18393.150390625 R = 0.70396316\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 1301/10000 [01:42<10:58, 13.20it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1170.5801605272293 Z = 38229.21875 R = 0.7020549\n"]},{"output_type":"stream","name":"stderr","text":[" 14%|█▍        | 1400/10000 [01:50<11:33, 12.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1220.7649707746505 Z = 80234.3046875 R = 0.71730995\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 1502/10000 [01:58<10:20, 13.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1267.7098390102387 Z = 182768.8125 R = 0.7316613\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▌        | 1600/10000 [02:06<11:49, 11.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1164.225108026266 Z = 386374.71875 R = 0.72075516\n"]},{"output_type":"stream","name":"stderr","text":[" 17%|█▋        | 1700/10000 [02:13<11:08, 12.41it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1112.5910564144142 Z = 803188.6875 R = 0.728353\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 1800/10000 [02:21<11:04, 12.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1145.0994919776917 Z = 1780112.5 R = 0.72457904\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 1901/10000 [02:29<10:45, 12.55it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1029.4303066825867 Z = 3552907.25 R = 0.72105324\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 2001/10000 [02:37<10:00, 13.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 938.5590150833129 Z = 6981356.5 R = 0.7160716\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 2101/10000 [02:45<09:58, 13.19it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 1050.3869185829162 Z = 15384602.0 R = 0.70918053\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 2201/10000 [02:53<10:15, 12.66it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 950.779866874218 Z = 31393388.0 R = 0.72441626\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 2301/10000 [03:00<09:59, 12.85it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 898.2285285949707 Z = 60838812.0 R = 0.7061335\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▍       | 2400/10000 [03:08<09:15, 13.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 821.1096924987436 Z = 114417504.0 R = 0.7069324\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 2501/10000 [03:16<10:03, 12.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 790.1760031890869 Z = 202618768.0 R = 0.7038062\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▌       | 2601/10000 [03:23<09:44, 12.65it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 784.3173875236512 Z = 365726976.0 R = 0.72905403\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 2701/10000 [03:31<09:28, 12.84it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 821.4208102631569 Z = 717818624.0 R = 0.71667105\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 2801/10000 [03:39<09:16, 12.95it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 738.200548043251 Z = 1336835072.0 R = 0.7236702\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▉       | 2901/10000 [03:46<09:04, 13.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 693.4246699523926 Z = 2311540736.0 R = 0.7314207\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 3001/10000 [03:54<08:59, 12.97it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 735.4140238401294 Z = 4470474240.0 R = 0.7183163\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███       | 3101/10000 [04:02<09:40, 11.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 685.3747248458862 Z = 7944258560.0 R = 0.71286094\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 3201/10000 [04:10<09:25, 12.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 674.9186244052648 Z = 14675017728.0 R = 0.7286759\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 3301/10000 [04:18<08:13, 13.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 645.8725379753113 Z = 27165022208.0 R = 0.7350485\n"]},{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 3401/10000 [04:25<08:29, 12.96it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 603.5433812856675 Z = 42664177664.0 R = 0.7149215\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 3501/10000 [04:33<08:56, 12.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 588.4444357299805 Z = 68137639936.0 R = 0.7052768\n"]},{"output_type":"stream","name":"stderr","text":[" 36%|███▌      | 3601/10000 [04:40<08:33, 12.47it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 583.7422772216797 Z = 111155134464.0 R = 0.72051996\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 3701/10000 [04:48<07:37, 13.78it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 539.4964152908325 Z = 147657408512.0 R = 0.72087824\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 3801/10000 [04:55<07:26, 13.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 555.39116563797 Z = 217634914304.0 R = 0.72097975\n"]},{"output_type":"stream","name":"stderr","text":[" 39%|███▉      | 3901/10000 [05:03<08:22, 12.13it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 559.0246370697022 Z = 371620151296.0 R = 0.7396141\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 4001/10000 [05:10<06:39, 15.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 540.4740592801571 Z = 586417438720.0 R = 0.7209557\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 4100/10000 [05:18<07:57, 12.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 533.9938843200914 Z = 882990579712.0 R = 0.7096495\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 4201/10000 [05:26<07:51, 12.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 520.3054505771398 Z = 1317412405248.0 R = 0.7213927\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 4301/10000 [05:33<07:44, 12.28it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 508.966451625824 Z = 2074455179264.0 R = 0.7234931\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 4400/10000 [05:42<10:11,  9.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 512.9160741615295 Z = 3084750946304.0 R = 0.7035259\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 4501/10000 [05:50<07:33, 12.14it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 499.06214121818545 Z = 4986249936896.0 R = 0.7127869\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▌     | 4601/10000 [05:58<07:16, 12.37it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 479.3938203954697 Z = 7366909100032.0 R = 0.712987\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|████▋     | 4701/10000 [06:05<06:38, 13.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 476.64253204345704 Z = 11266024275968.0 R = 0.72218305\n"]},{"output_type":"stream","name":"stderr","text":[" 48%|████▊     | 4800/10000 [06:13<06:33, 13.20it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 463.33719160437585 Z = 16418032582656.0 R = 0.7342216\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 4901/10000 [06:21<06:27, 13.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 451.0977294826508 Z = 21616442474496.0 R = 0.71623254\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 5001/10000 [06:28<06:54, 12.07it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 454.2753672790527 Z = 31063682318336.0 R = 0.7064178\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 5101/10000 [06:36<06:40, 12.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 444.0702893638611 Z = 46300292710400.0 R = 0.72287476\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 5200/10000 [06:43<05:38, 14.20it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 450.37336729466915 Z = 62891512299520.0 R = 0.7128612\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 5301/10000 [06:51<05:54, 13.25it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 426.16747052431106 Z = 85889900347392.0 R = 0.71634173\n"]},{"output_type":"stream","name":"stderr","text":[" 54%|█████▍    | 5401/10000 [06:59<05:34, 13.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 433.1381192016602 Z = 125770131308544.0 R = 0.70919496\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 5501/10000 [07:07<05:17, 14.16it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 450.5505761182308 Z = 173844220346368.0 R = 0.7159178\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 5601/10000 [07:14<05:45, 12.74it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 425.14555021077393 Z = 211537641865216.0 R = 0.71247375\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 5700/10000 [07:22<06:00, 11.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 402.6125224667787 Z = 302590914985984.0 R = 0.7180134\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 5800/10000 [07:30<05:59, 11.67it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 387.22723882198335 Z = 466215512309760.0 R = 0.72484994\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▉    | 5900/10000 [07:38<04:48, 14.19it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 398.7714004611969 Z = 686270141431808.0 R = 0.71586275\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 6000/10000 [07:46<05:07, 13.00it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 411.241635594368 Z = 845706038345728.0 R = 0.71707964\n"]},{"output_type":"stream","name":"stderr","text":[" 61%|██████    | 6101/10000 [07:53<05:21, 12.13it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 413.4377154254913 Z = 1049459219759104.0 R = 0.71797204\n"]},{"output_type":"stream","name":"stderr","text":[" 62%|██████▏   | 6201/10000 [08:01<04:31, 13.97it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 418.6441455078125 Z = 1377983885475840.0 R = 0.722102\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 6301/10000 [08:09<05:09, 11.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 411.73560913085936 Z = 1655117321338880.0 R = 0.71778715\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 6401/10000 [08:17<05:02, 11.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 391.9553090023994 Z = 2121591974526976.0 R = 0.71917236\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 6501/10000 [08:24<04:49, 12.07it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 412.9705519199371 Z = 2568282263519232.0 R = 0.7210734\n"]},{"output_type":"stream","name":"stderr","text":[" 66%|██████▌   | 6601/10000 [08:32<04:29, 12.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 381.34660049438475 Z = 3461265825464320.0 R = 0.71844214\n"]},{"output_type":"stream","name":"stderr","text":[" 67%|██████▋   | 6701/10000 [08:40<03:57, 13.89it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 365.36071060180666 Z = 4729022596513792.0 R = 0.7224574\n"]},{"output_type":"stream","name":"stderr","text":[" 68%|██████▊   | 6801/10000 [08:48<03:56, 13.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 417.21678541183473 Z = 5182257610358784.0 R = 0.73131865\n"]},{"output_type":"stream","name":"stderr","text":[" 69%|██████▉   | 6901/10000 [08:55<03:59, 12.96it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 404.11620688349007 Z = 5990669239713792.0 R = 0.7247574\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 7001/10000 [09:03<04:13, 11.82it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 342.93323394775393 Z = 7938799833186304.0 R = 0.7115072\n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 7100/10000 [09:11<03:44, 12.90it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 388.4260768699646 Z = 9561054614913024.0 R = 0.71470445\n"]},{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 7200/10000 [09:19<03:37, 12.88it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 378.8931120300293 Z = 1.1921415095713792e+16 R = 0.7359786\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 7301/10000 [09:26<03:36, 12.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 419.8326661682129 Z = 1.2328401901715456e+16 R = 0.6978981\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 7401/10000 [09:34<03:41, 11.72it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 336.4191753292084 Z = 1.674506816978944e+16 R = 0.7155323\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 7500/10000 [09:42<03:14, 12.85it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 339.49521798610687 Z = 2.2797521050927104e+16 R = 0.72154236\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▌  | 7600/10000 [09:50<03:16, 12.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 358.3052207946777 Z = 2.7592894986584064e+16 R = 0.70945513\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 7700/10000 [09:58<03:03, 12.55it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 360.7847782945633 Z = 3.374207053122765e+16 R = 0.72573733\n"]},{"output_type":"stream","name":"stderr","text":[" 78%|███████▊  | 7800/10000 [10:06<03:08, 11.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 385.3562548017502 Z = 3.684725028185702e+16 R = 0.7235383\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 7900/10000 [10:13<02:50, 12.32it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 363.4300739449263 Z = 4.307847043927245e+16 R = 0.723336\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 8000/10000 [10:21<02:32, 13.11it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 360.9112969917059 Z = 5.078557450357965e+16 R = 0.71305776\n"]},{"output_type":"stream","name":"stderr","text":[" 81%|████████  | 8100/10000 [10:29<02:43, 11.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 316.44311512470244 Z = 6.477559724664422e+16 R = 0.7208471\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|████████▏ | 8202/10000 [10:37<01:54, 15.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","loss = 361.2398410844803 Z = 7.7358150616875e+16 R = 0.7054594\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10000/10000 [10:56<00:00, 15.22it/s]\n"]}]},{"cell_type":"code","source":["samples = []\n","\n","for it in tqdm.trange(100):\n","    nan_flag = False\n","    generated = torch.LongTensor(batch_size, max_len)  # upcoming output\n","    generated.fill_(params.pad_index)                  # fill upcoming ouput with <PAD>\n","    generated[:,0].fill_(params.bos_index)             # <BOS> (start token), initial state\n","\n","    # Length of already generated sequences : 1 because of <BOS>\n","    #gen_len = (generated != params.pad_index).long().sum(dim=1)\n","    gen_len = torch.LongTensor(batch_size,).fill_(1) # (batch_size,)\n","    # 1 (True) if the generation of the sequence is not yet finished, 0 (False) otherwise\n","    unfinished_sents = gen_len.clone().fill_(1) # (batch_size,)\n","    # Length of already generated sequences : 1 because of <BOS>\n","    cur_len = 1 \n","\n","    while cur_len < max_len:\n","        state = generated[:,:cur_len] + 0 # (bs, cur_len)\n","        with torch.no_grad():\n","            tensor = model(state.to(device), lengths=gen_len.to(device)) # (bs, cur_len, vocab_size)\n","        #scores = tensor[:,0] # (bs, vocab_size) : use last word for prediction\n","        scores = tensor.sum(dim=1) # (bs, vocab_size) \n","        # fixed length generation\n","        \n","        scores = scores.log_softmax(1)\n","        sample_temperature = 1\n","        probs = F.softmax(scores / sample_temperature, dim=1)\n","        #next_words = torch.distributions.categorical.Categorical(probs=probs).sample()\n","        try:\n","          next_words = torch.multinomial(probs, 1).squeeze(1)\n","        except:\n","          nan_flag = True\n","          break\n","        # update generations / lengths / finished sentences / current length\n","\n","        generated[:,cur_len] = next_words.cpu() * unfinished_sents + params.pad_index * (1 - unfinished_sents)\n","        gen_len.add_(unfinished_sents) # add 1 to the length of the unfinished sentences\n","        unfinished_sents.mul_(next_words.cpu().ne(params.eos_index).long()) # as soon as we generate <EOS>, set unfinished_sents to 0\n","        cur_len = cur_len + 1\n","      \n","        # stop when there is a <EOS> in each sentence, or if we exceed the maximul length\n","        if unfinished_sents.max() == 0:\n","            break\n","\n","    #R = reward_function(generated, reward_coef, lambda_, beta).to(device)\n","    if nan_flag == True:\n","      nan_flag = False\n","      continue\n","\n","    samples.extend(generated)  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGVmQtz4FLg8","executionInfo":{"status":"ok","timestamp":1656902513484,"user_tz":-480,"elapsed":995,"user":{"displayName":"赵为","userId":"02938840416374213176"}},"outputId":"c55788df-0f94-4c57-84ce-fabfb991945f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [00:00<00:00, 125.81it/s]\n"]}]}]}